{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysql.connector import connect as ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "connection = ct(\n",
    "    host='localhost',\n",
    "    port=3306,\n",
    "    user='root',\n",
    "    password='Akra@18122003',  \n",
    ")\n",
    "\n",
    "print(connection.is_connected())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID      CustomerName                         Email  Gender  Age  \\\n",
      "0           1     Emma Anderson     emma.anderson@example.com    Male   50   \n",
      "1           2       Sarah Brown       sarah.brown@example.com  Female   37   \n",
      "2           3  Robert Hernandez  robert.hernandez@example.com  Female   26   \n",
      "3           4      David Garcia      david.garcia@example.com    Male   25   \n",
      "4           5       Emma Miller       emma.miller@example.com  Female   41   \n",
      "\n",
      "   GeographyID  \n",
      "0            2  \n",
      "1            4  \n",
      "2            6  \n",
      "3            8  \n",
      "4            4  \n",
      "   JourneyID  CustomerID  ProductID   VisitDate        Stage    Action  \\\n",
      "0          1          64         18  2024-06-10     Checkout  Drop-off   \n",
      "1          2          94         11  2025-07-09     Checkout  Drop-off   \n",
      "2          3          34          8  2024-06-14  ProductPage      View   \n",
      "3          4          33         18  2025-05-28     Checkout  Drop-off   \n",
      "4          5          91         10  2023-02-11     Homepage     Click   \n",
      "\n",
      "   Duration  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2     235.0  \n",
      "3       NaN  \n",
      "4     156.0  \n",
      "   ReviewID  CustomerID  ProductID  ReviewDate  Rating  \\\n",
      "0         1          77         18  2023-12-23       3   \n",
      "1         2          80         19  2024-12-25       5   \n",
      "2         3          50         13  2025-01-26       4   \n",
      "3         4          78         15  2025-04-21       3   \n",
      "4         5          64          2  2023-07-16       3   \n",
      "\n",
      "                                 ReviewText  \n",
      "0   Average  experience,  nothing  special.  \n",
      "1            The  quality  is    top-notch.  \n",
      "2   Five  stars  for  the  quick  delivery.  \n",
      "3  Good  quality,  but  could  be  cheaper.  \n",
      "4   Average  experience,  nothing  special.  \n",
      "   EngagementID  ContentID ContentType  Likes EngagementDate  CampaignID  \\\n",
      "0             1         39        Blog    190     2023-08-30           1   \n",
      "1             2         48        Blog    114     2023-03-28          18   \n",
      "2             3         16       video     32     2023-12-08           7   \n",
      "3             4         43       Video     17     2025-01-21          19   \n",
      "4             5         16  newsletter    306     2024-02-21           6   \n",
      "\n",
      "   ProductID ViewsClicksCombined  \n",
      "0          9            1883-671  \n",
      "1         20            5280-532  \n",
      "2         14            1905-204  \n",
      "3         20            2766-257  \n",
      "4         15           5116-1524  \n",
      "   GeographyID  Country    City\n",
      "0            1       UK  London\n",
      "1            2  Germany  Berlin\n",
      "2            3   France   Paris\n",
      "3            4    Spain  Madrid\n",
      "4            5    Italy    Rome\n",
      "   ProductID      ProductName Category   Price\n",
      "0          1    Running Shoes   Sports  223.75\n",
      "1          2  Fitness Tracker   Sports  196.68\n",
      "2          3         Yoga Mat   Sports  485.32\n",
      "3          4        Dumbbells   Sports   26.21\n",
      "4          5      Soccer Ball   Sports   41.26\n"
     ]
    }
   ],
   "source": [
    "customers = pd.read_csv('customers.csv')  # Replace 'your_file.csv' with your file path\n",
    "print(customers.head())\n",
    "\n",
    "customer_journey = pd.read_csv('customer_journey.csv') \n",
    "print(customer_journey.head())\n",
    "\n",
    "customer_reviews = pd.read_csv('customer_reviews.csv')  \n",
    "print(customer_reviews.head())\n",
    "\n",
    "engagement_data = pd.read_csv('engagement_data.csv')  \n",
    "print(engagement_data.head())\n",
    "\n",
    "geography = pd.read_csv('geography.csv')  \n",
    "print(geography.head())\n",
    "\n",
    "products = pd.read_csv('products.csv')  \n",
    "print(products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Step 1: Establish a connection to the MySQL database using the existing connection\n",
    "engine = create_engine('mysql+mysqlconnector://root:Akra@18122003@localhost:3306/database1_db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank values removed from all dataframes.\n"
     ]
    }
   ],
   "source": [
    "# Remove all blank values from the dataframes\n",
    "customers.dropna(inplace=True)\n",
    "customer_journey.dropna(inplace=True)\n",
    "customer_reviews.dropna(inplace=True)\n",
    "engagement_data.dropna(inplace=True)\n",
    "geography.dropna(inplace=True)\n",
    "products.dropna(inplace=True)\n",
    "\n",
    "print(\"Blank values removed from all dataframes.\")\n",
    "\n",
    "\n",
    "# customers_zero = customers.fillna(0)\n",
    "# customer_journey_zero = customer_journey.fillna(0)          \n",
    "# customer_reviews_zero = customer_reviews.fillna(0)\n",
    "# engagement_data_zero = engagement_data.fillna(0)\n",
    "# geography_zero = geography.fillna(0)\n",
    "# products_zero = products.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in customers dataframe:\n",
      " CustomerID      0\n",
      "CustomerName    0\n",
      "Email           0\n",
      "Gender          0\n",
      "Age             0\n",
      "GeographyID     0\n",
      "dtype: int64\n",
      "Missing values in customer_journey dataframe:\n",
      " JourneyID     0\n",
      "CustomerID    0\n",
      "ProductID     0\n",
      "VisitDate     0\n",
      "Stage         0\n",
      "Action        0\n",
      "Duration      0\n",
      "dtype: int64\n",
      "Missing values in customer_reviews dataframe:\n",
      " ReviewID      0\n",
      "CustomerID    0\n",
      "ProductID     0\n",
      "ReviewDate    0\n",
      "Rating        0\n",
      "ReviewText    0\n",
      "dtype: int64\n",
      "Missing values in engagement_data dataframe:\n",
      " EngagementID           0\n",
      "ContentID              0\n",
      "ContentType            0\n",
      "Likes                  0\n",
      "EngagementDate         0\n",
      "CampaignID             0\n",
      "ProductID              0\n",
      "ViewsClicksCombined    0\n",
      "dtype: int64\n",
      "Missing values in geography dataframe:\n",
      " GeographyID    0\n",
      "Country        0\n",
      "City           0\n",
      "dtype: int64\n",
      "Missing values in products dataframe:\n",
      " ProductID      0\n",
      "ProductName    0\n",
      "Category       0\n",
      "Price          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each dataframe\n",
    "print(\"Missing values in customers dataframe:\\n\", customers.isnull().sum())\n",
    "print(\"Missing values in customer_journey dataframe:\\n\", customer_journey.isnull().sum())\n",
    "print(\"Missing values in customer_reviews dataframe:\\n\", customer_reviews.isnull().sum())\n",
    "print(\"Missing values in engagement_data dataframe:\\n\", engagement_data.isnull().sum())\n",
    "print(\"Missing values in geography dataframe:\\n\", geography.isnull().sum())\n",
    "print(\"Missing values in products dataframe:\\n\", products.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean price of products is: 205.4055\n"
     ]
    }
   ],
   "source": [
    "mean_price = products['Price'].mean()\n",
    "print(f\"The mean price of products is: {mean_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created successfully.\n",
      "Tables created successfully.\n"
     ]
    }
   ],
   "source": [
    "from mysql.connector import errorcode\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "# Database configuration\n",
    "db_config = {\n",
    "    'user': 'root',\n",
    "    'password': 'Akra@18122003',\n",
    "    'host': 'localhost',\n",
    "    'database': 'database1_db'\n",
    "}\n",
    "\n",
    "# Create a new database\n",
    "try:\n",
    "    cnx = mysql.connector.connect(user=db_config['user'], password=db_config['password'], host=db_config['host'])\n",
    "    cursor = cnx.cursor()\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS database1_db\")\n",
    "    print(\"Database created successfully.\")\n",
    "except mysql.connector.Error as err:\n",
    "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "        print(\"Something is wrong with your user name or password\")\n",
    "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(\"Database does not exist\")\n",
    "    else:\n",
    "        print(err)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "\n",
    "# Create tables for each CSV file\n",
    "try:\n",
    "    cnx = mysql.connector.connect(**db_config)\n",
    "    cursor = cnx.cursor()\n",
    "\n",
    "    # Create Customers table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Customers (\n",
    "        CustomerID INT PRIMARY KEY,\n",
    "        CustomerName VARCHAR(255),\n",
    "        Email VARCHAR(255),\n",
    "        Gender VARCHAR(10),\n",
    "        Age INT,\n",
    "        GeographyID INT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Create Geography table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Geography (\n",
    "        GeographyID INT PRIMARY KEY,\n",
    "        Country VARCHAR(255),\n",
    "        City VARCHAR(255)\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Create Products table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Products (\n",
    "        ProductID INT PRIMARY KEY,\n",
    "        ProductName VARCHAR(255),\n",
    "        Category VARCHAR(255),\n",
    "        Price FLOAT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Create Reviews table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Reviews (\n",
    "        ReviewID INT PRIMARY KEY,\n",
    "        CustomerID INT,\n",
    "        ProductID INT,\n",
    "        ReviewDate DATE,\n",
    "        Rating INT,\n",
    "        ReviewText TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Create Journey table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Journey (\n",
    "        JourneyID INT PRIMARY KEY,\n",
    "        CustomerID INT,\n",
    "        ProductID INT,\n",
    "        VisitDate DATE,\n",
    "        Stage VARCHAR(255),\n",
    "        Action VARCHAR(255),\n",
    "        Duration FLOAT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Create Engagement table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Engagement (\n",
    "        EngagementID INT PRIMARY KEY,\n",
    "        ContentID INT,\n",
    "        ContentType VARCHAR(255),\n",
    "        Likes INT,\n",
    "        EngagementDate DATE,\n",
    "        CampaignID INT,\n",
    "        ProductID INT,\n",
    "        Views INT,\n",
    "        Clicks INT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"Tables created successfully.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer journey behavior → Identify bottlenecks in the purchase process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Journey Stages and Counts:\n",
      "         Stage  Count\n",
      "1     Homepage     50\n",
      "2  ProductPage     24\n",
      "0     Checkout      6\n",
      "3     homepage      4\n",
      "4  productpage      2\n",
      "\n",
      "Average Duration Spent at Each Stage:\n",
      "         Stage  AverageDuration\n",
      "0     Checkout       150.166667\n",
      "1     Homepage       158.520000\n",
      "2  ProductPage       186.666667\n",
      "3     homepage       185.750000\n",
      "4  productpage       136.000000\n",
      "\n",
      "Customer Journey Analysis (Counts and Average Duration):\n",
      "         Stage  Count  AverageDuration\n",
      "0     Homepage     50       158.520000\n",
      "1  ProductPage     24       186.666667\n",
      "2     Checkout      6       150.166667\n",
      "3     homepage      4       185.750000\n",
      "4  productpage      2       136.000000\n"
     ]
    }
   ],
   "source": [
    "# Group customer journey data by 'Stage' and count the number of occurrences\n",
    "stage_counts = customer_journey.groupby('Stage').size().reset_index(name='Count')\n",
    "\n",
    "#  Sort the stages by count to identify potential bottlenecks\n",
    "stage_counts = stage_counts.sort_values(by='Count', ascending=False)\n",
    "\n",
    "print(\"Customer Journey Stages and Counts:\")\n",
    "print(stage_counts)\n",
    "\n",
    "# Calculate the average duration spent at each stage\n",
    "average_duration_per_stage = customer_journey.groupby('Stage')['Duration'].mean().reset_index(name='AverageDuration')\n",
    "\n",
    "print(\"\\nAverage Duration Spent at Each Stage:\")\n",
    "print(average_duration_per_stage)\n",
    "\n",
    "# Optional: Merge the two datasets for a comprehensive view\n",
    "journey_analysis = pd.merge(stage_counts, average_duration_per_stage, on='Stage')\n",
    "\n",
    "print(\"\\nCustomer Journey Analysis (Counts and Average Duration):\")\n",
    "print(journey_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer reviews & feedback → Understand sentiment and satisfaction trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satisfaction Trends (Rating Distribution):\n",
      "   Rating  Count\n",
      "0       1      3\n",
      "1       2      6\n",
      "2       3     29\n",
      "3       4     39\n",
      "4       5     23\n",
      "\n",
      "Average Rating per Product:\n",
      "    ProductID  AverageRating\n",
      "0           1       4.000000\n",
      "1           2       3.571429\n",
      "2           3       3.714286\n",
      "3           4       3.000000\n",
      "4           5       4.000000\n",
      "5           6       3.857143\n",
      "6           7       2.666667\n",
      "7           8       5.000000\n",
      "8           9       3.400000\n",
      "9          10       3.500000\n",
      "10         11       4.000000\n",
      "11         12       3.000000\n",
      "12         13       3.666667\n",
      "13         15       4.000000\n",
      "14         16       3.400000\n",
      "15         17       3.888889\n",
      "16         18       4.000000\n",
      "17         19       4.400000\n",
      "18         20       4.000000\n",
      "\n",
      "Most Common Words in Reviews (Sentiment Analysis):\n",
      "[('the', 57), ('was', 22), ('product', 20), ('quality', 19), ('for', 18), ('five', 17), ('stars', 17), ('quick', 17), ('delivery', 17), ('is', 15)]\n"
     ]
    }
   ],
   "source": [
    "# Group customer reviews by Rating to understand satisfaction trends\n",
    "rating_trends = customer_reviews.groupby('Rating').size().reset_index(name='Count')\n",
    "print(\"Satisfaction Trends (Rating Distribution):\")\n",
    "print(rating_trends)\n",
    "\n",
    "# Analyze the average rating for each product to understand product satisfaction\n",
    "product_satisfaction = customer_reviews.groupby('ProductID')['Rating'].mean().reset_index(name='AverageRating')\n",
    "print(\"\\nAverage Rating per Product:\")\n",
    "print(product_satisfaction)\n",
    "\n",
    "# Analyzing the most common words in ReviewText to understand sentiment trends\n",
    "\n",
    "# Combine all review texts into a single string\n",
    "all_reviews = \" \".join(customer_reviews['ReviewText'])\n",
    "\n",
    "# Clean and tokenize the text\n",
    "words = re.findall(r'\\b\\w+\\b', all_reviews.lower())\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# Display the most common words\n",
    "common_words = word_counts.most_common(10)\n",
    "print(\"\\nMost Common Words in Reviews (Sentiment Analysis):\")\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marketing effectiveness → Measure the impact of engagement on conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marketing Effectiveness (Conversion Rate by Product):\n",
      "    ProductID  EngagementCount  PurchaseCount  ConversionRate\n",
      "0           1                5            0.0        0.000000\n",
      "1           2                6            1.0       16.666667\n",
      "2           3                4            0.0        0.000000\n",
      "3           4                4            0.0        0.000000\n",
      "4           5                2            0.0        0.000000\n",
      "5           6                5            0.0        0.000000\n",
      "6           7                8            0.0        0.000000\n",
      "7           8                7            0.0        0.000000\n",
      "8           9                4            0.0        0.000000\n",
      "9          10                4            0.0        0.000000\n",
      "10         11                2            0.0        0.000000\n",
      "11         12                5            0.0        0.000000\n",
      "12         13                4            0.0        0.000000\n",
      "13         14                4            0.0        0.000000\n",
      "14         15                7            2.0       28.571429\n",
      "15         16                8            1.0       12.500000\n",
      "16         17                5            2.0       40.000000\n",
      "17         18                4            0.0        0.000000\n",
      "18         19                5            0.0        0.000000\n",
      "19         20                7            0.0        0.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate conversion rate based on engagement data\n",
    "# Conversion is defined as the number of purchases divided by the total number of engagements\n",
    "\n",
    "# Filter customer journey data for 'Purchase' actions\n",
    "purchases = customer_journey[customer_journey['Action'].str.lower() == 'purchase']\n",
    "\n",
    "# Group by ProductID to calculate total purchases\n",
    "purchase_counts = purchases.groupby('ProductID').size().reset_index(name='PurchaseCount')\n",
    "\n",
    "# Group engagement data by ProductID to calculate total engagements\n",
    "engagement_counts = engagement_data.groupby('ProductID').size().reset_index(name='EngagementCount')\n",
    "\n",
    "# Merge the two datasets on ProductID\n",
    "conversion_data = pd.merge(engagement_counts, purchase_counts, on='ProductID', how='left')\n",
    "\n",
    "# Fill NaN values in PurchaseCount with 0 (for products with no purchases)\n",
    "conversion_data['PurchaseCount'] = conversion_data['PurchaseCount'].fillna(0)\n",
    "\n",
    "# Calculate conversion rate\n",
    "conversion_data['ConversionRate'] = (conversion_data['PurchaseCount'] / conversion_data['EngagementCount']) * 100\n",
    "\n",
    "# Display the conversion data\n",
    "print(\"Marketing Effectiveness (Conversion Rate by Product):\")\n",
    "print(conversion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product & demographic analysis → Identify high-performing products and customer segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-Performing Products:\n",
      "    ProductID  AverageRating  EngagementCount  PurchaseCount  ConversionRate\n",
      "13         15            4.0                7            2.0       28.571429\n",
      "\n",
      "Customer Demographics for High-Performing Products:\n",
      "   Gender  Age  PurchaseCount\n",
      "0  Female   35              1\n",
      "1    Male   22              1\n"
     ]
    }
   ],
   "source": [
    "# Product & demographic analysis → Identify high-performing products and customer segments.\n",
    "\n",
    "# Identify high-performing products based on average rating and conversion rate\n",
    "high_performing_products = pd.merge(product_satisfaction, conversion_data, on='ProductID')\n",
    "high_performing_products = high_performing_products[\n",
    "    (high_performing_products['AverageRating'] >= 4) & (high_performing_products['ConversionRate'] > 20)\n",
    "]\n",
    "print(\"High-Performing Products:\")\n",
    "print(high_performing_products)\n",
    "\n",
    "# Analyze customer demographics for high-performing products\n",
    "# Filter customer journey data for purchases of high-performing products\n",
    "high_perf_product_ids = high_performing_products['ProductID'].tolist()\n",
    "high_perf_purchases = purchases[purchases['ProductID'].isin(high_perf_product_ids)]\n",
    "\n",
    "# Merge with customers data to get demographic information\n",
    "customer_segments = pd.merge(high_perf_purchases, customers, on='CustomerID')\n",
    "\n",
    "# Group by demographics (e.g., Gender, Age) to identify trends\n",
    "demographic_analysis = customer_segments.groupby(['Gender', 'Age']).size().reset_index(name='PurchaseCount')\n",
    "print(\"\\nCustomer Demographics for High-Performing Products:\")\n",
    "print(demographic_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Customer Journey & Engagement Analysis (SQL):\n",
    "1. Identify drop-off points in the customer journey.\n",
    "2. Find common actions leading to successful conversions.\n",
    "3. Calculate average duration per stage for engagement insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Journey Stages with Drop-Off Analysis:\n",
      "         Stage  Count  Percentage    DropOff\n",
      "1     Homepage     50   58.139535   0.000000\n",
      "2  ProductPage     24   27.906977  30.232558\n",
      "0     Checkout      6    6.976744  20.930233\n",
      "3     homepage      4    4.651163   2.325581\n",
      "4  productpage      2    2.325581   2.325581\n"
     ]
    }
   ],
   "source": [
    "# Identify drop-off points in the customer journey using pandas\n",
    "\n",
    "#  Group customer journey data by 'Stage' and count the number of occurrences\n",
    "stage_counts = customer_journey.groupby('Stage').size().reset_index(name='Count')\n",
    "\n",
    "#  Sort the stages by count to identify potential drop-off points\n",
    "stage_counts = stage_counts.sort_values(by='Count', ascending=False)\n",
    "\n",
    "#  Calculate the percentage of customers at each stage\n",
    "total_customers = stage_counts['Count'].sum()\n",
    "stage_counts['Percentage'] = (stage_counts['Count'] / total_customers) * 100\n",
    "\n",
    "# Identify stages with significant drop-offs\n",
    "stage_counts['DropOff'] = stage_counts['Percentage'].diff().fillna(0).abs()\n",
    "\n",
    "print(\"Customer Journey Stages with Drop-Off Analysis:\")\n",
    "print(stage_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find common actions leading to successful conversions using pandas\n",
    "\n",
    "# # Filter customer journey data for 'Purchase' actions\n",
    "# purchases = customer_journey[customer_journey['Action'].str.lower() == 'purchase']\n",
    "\n",
    "# # Merge the purchases data with the customer journey data to find preceding actions\n",
    "# merged_data = pd.merge(\n",
    "#     customer_journey,\n",
    "#     purchases[['CustomerID', 'ProductID', 'JourneyID']],\n",
    "#     on=['CustomerID', 'ProductID'],\n",
    "#     suffixes=('', '_Purchase')\n",
    "# )\n",
    "\n",
    "# # Filter for actions that occurred before the purchase\n",
    "# merged_data = merged_data[merged_data['JourneyID'] < merged_data['JourneyID_Purchase']]\n",
    "\n",
    "# # Group by 'Action' to count occurrences of actions leading to purchases\n",
    "# common_actions = merged_data.groupby('Action').size().reset_index(name='Count')\n",
    "\n",
    "# # Sort by count to find the most common actions\n",
    "# common_actions = common_actions.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# print(\"Common Actions Leading to Successful Conversions:\")\n",
    "# print(common_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Duration Per Stage:\n",
      "         Stage  AverageDuration\n",
      "0     Checkout       150.166667\n",
      "1     Homepage       158.520000\n",
      "2  ProductPage       186.666667\n",
      "3     homepage       185.750000\n",
      "4  productpage       136.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average duration per stage for engagement insights\n",
    "average_duration_per_stage = customer_journey.groupby('Stage')['Duration'].mean().reset_index(name='AverageDuration')\n",
    "\n",
    "# Display the results\n",
    "print(\"Average Duration Per Stage:\")\n",
    "print(average_duration_per_stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Reviews Analysis (SQL & Python):\n",
    "1. Identify highest-rated and lowest-rated products using SQL.\n",
    "2. Perform basic sentiment analysis in Python.\n",
    "3. Correlate review trends with product performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest-Rated Product:\n",
      "   ProductID  AverageRating\n",
      "0          8            5.0\n",
      "\n",
      "Lowest-Rated Product:\n",
      "   ProductID  AverageRating\n",
      "0          7         2.6667\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create a connection to the database\n",
    "engine = create_engine('mysql+mysqlconnector://root:Akra%4018122003@localhost:3306/database1_db')\n",
    "\n",
    "#  Create the customer_reviews table if it doesn't exist\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS customer_reviews (\n",
    "\tReviewID INT PRIMARY KEY,\n",
    "\tCustomerID INT,\n",
    "\tProductID INT,\n",
    "\tReviewDate DATE,\n",
    "\tRating INT,\n",
    "\tReviewText TEXT\n",
    ");\n",
    "\"\"\"\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "with engine.connect() as connection:\n",
    "\tconnection.execute(text(create_table_query))\n",
    "\n",
    "#  Populate the customer_reviews table with data from the DataFrame\n",
    "customer_reviews.to_sql('customer_reviews', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Query to find the highest-rated product\n",
    "highest_rated_query = \"\"\"\n",
    "SELECT ProductID, AVG(Rating) AS AverageRating\n",
    "FROM customer_reviews\n",
    "GROUP BY ProductID\n",
    "ORDER BY AverageRating DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "# Query to find the lowest-rated product\n",
    "lowest_rated_query = \"\"\"\n",
    "SELECT ProductID, AVG(Rating) AS AverageRating\n",
    "FROM customer_reviews\n",
    "GROUP BY ProductID\n",
    "ORDER BY AverageRating ASC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the queries\n",
    "highest_rated_product = pd.read_sql(highest_rated_query, engine)\n",
    "lowest_rated_product = pd.read_sql(lowest_rated_query, engine)\n",
    "\n",
    "# Display the results\n",
    "print(\"Highest-Rated Product:\")\n",
    "print(highest_rated_product)\n",
    "\n",
    "print(\"\\nLowest-Rated Product:\")\n",
    "print(lowest_rated_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in c:\\users\\ayush kumar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\ayush kumar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\ayush kumar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ayush kumar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ayush kumar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk>=3.9->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayush kumar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk>=3.9->textblob) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush kumar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Ayush kumar\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install textblob using pip\n",
    "!pip install textblob\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "                                               Review  Polarity  Subjectivity\n",
      "0              Average  experience,  nothing  special  0.103571      0.485714\n",
      "1                       The  quality  is    top-notch  1.000000      1.000000\n",
      "2              Five  stars  for  the  quick  delivery  0.333333      0.500000\n",
      "3             Good  quality,  but  could  be  cheaper  0.700000      0.600000\n",
      "4              Average  experience,  nothing  special  0.103571      0.485714\n",
      "..                                                ...       ...           ...\n",
      "80  Shipping  was  fast  and  the  item  was  well...  0.200000      0.600000\n",
      "81            Good  quality,  but  could  be  cheaper  0.700000      0.600000\n",
      "82  The  product  is  okay,  but  the  instruction...  0.500000      0.500000\n",
      "83  Exceeded  my  expectations! Average  experienc...  0.103571      0.485714\n",
      "84                             Not  worth  the  money -0.150000      0.100000\n",
      "\n",
      "[85 rows x 3 columns]\n",
      "\n",
      "Average Polarity: 0.40775490196078434\n",
      "Average Subjectivity: 0.5970549019607844\n"
     ]
    }
   ],
   "source": [
    "# Perform basic sentiment analysis on the `all_reviews` variable\n",
    "# Split the reviews into individual sentences\n",
    "reviews = all_reviews.split('.')\n",
    "\n",
    "# Analyze the sentiment of each review\n",
    "sentiment_results = []\n",
    "for review in reviews:\n",
    "    if review.strip():  # Ignore empty strings\n",
    "        analysis = TextBlob(review.strip())\n",
    "        sentiment_results.append({\n",
    "            'Review': review.strip(),\n",
    "            'Polarity': analysis.sentiment.polarity,\n",
    "            'Subjectivity': analysis.sentiment.subjectivity\n",
    "        })\n",
    "\n",
    "# Convert the results into a DataFrame for better visualization\n",
    "sentiment_df = pd.DataFrame(sentiment_results)\n",
    "\n",
    "# Display the sentiment analysis results\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "print(sentiment_df)\n",
    "\n",
    "# Optional: Calculate overall sentiment statistics\n",
    "average_polarity = sentiment_df['Polarity'].mean()\n",
    "average_subjectivity = sentiment_df['Subjectivity'].mean()\n",
    "\n",
    "print(f\"\\nAverage Polarity: {average_polarity}\")\n",
    "print(f\"Average Subjectivity: {average_subjectivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated Data (Review Trends and Product Performance):\n",
      "    ProductID  AverageRating  ReviewCount  EngagementCount  PurchaseCount  \\\n",
      "0           1       4.000000            4                5            0.0   \n",
      "1           2       3.571429            7                6            1.0   \n",
      "2           3       3.714286            7                4            0.0   \n",
      "3           4       3.000000            5                4            0.0   \n",
      "4           5       4.000000            3                2            0.0   \n",
      "5           6       3.857143            7                5            0.0   \n",
      "6           7       2.666667            3                8            0.0   \n",
      "7           8       5.000000            3                7            0.0   \n",
      "8           9       3.400000            5                4            0.0   \n",
      "9          10       3.500000            4                4            0.0   \n",
      "10         11       4.000000            6                2            0.0   \n",
      "11         12       3.000000            2                5            0.0   \n",
      "12         13       3.666667            9                4            0.0   \n",
      "13         15       4.000000            6                7            2.0   \n",
      "14         16       3.400000           10                8            1.0   \n",
      "15         17       3.888889            9                5            2.0   \n",
      "16         18       4.000000            3                4            0.0   \n",
      "17         19       4.400000            5                5            0.0   \n",
      "18         20       4.000000            2                7            0.0   \n",
      "\n",
      "    ConversionRate  \n",
      "0         0.000000  \n",
      "1        16.666667  \n",
      "2         0.000000  \n",
      "3         0.000000  \n",
      "4         0.000000  \n",
      "5         0.000000  \n",
      "6         0.000000  \n",
      "7         0.000000  \n",
      "8         0.000000  \n",
      "9         0.000000  \n",
      "10        0.000000  \n",
      "11        0.000000  \n",
      "12        0.000000  \n",
      "13       28.571429  \n",
      "14       12.500000  \n",
      "15       40.000000  \n",
      "16        0.000000  \n",
      "17        0.000000  \n",
      "18        0.000000  \n",
      "\n",
      "Correlation Matrix:\n",
      "                AverageRating  ReviewCount  ConversionRate\n",
      "AverageRating        1.000000    -0.044509        0.057932\n",
      "ReviewCount         -0.044509     1.000000        0.519344\n",
      "ConversionRate       0.057932     0.519344        1.000000\n"
     ]
    }
   ],
   "source": [
    "#Merge customer reviews with product satisfaction data\n",
    "review_performance = pd.merge(customer_reviews, product_satisfaction, on='ProductID')\n",
    "\n",
    "# Group by ProductID to calculate average rating and count of reviews\n",
    "review_trends = review_performance.groupby('ProductID').agg(\n",
    "    AverageRating=('Rating', 'mean'),\n",
    "    ReviewCount=('ReviewID', 'count')\n",
    ").reset_index()\n",
    "\n",
    "#  Merge with conversion data to include conversion rates\n",
    "correlated_data = pd.merge(review_trends, conversion_data, on='ProductID')\n",
    "\n",
    "#  Analyze correlation between review trends and conversion rates\n",
    "correlation = correlated_data[['AverageRating', 'ReviewCount', 'ConversionRate']].corr()\n",
    "\n",
    "# Display the results\n",
    "print(\"Correlated Data (Review Trends and Product Performance):\")\n",
    "print(correlated_data)\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marketing Effectiveness (SQL):\n",
    "1. Calculate customer retention rate.\n",
    "2. Compare repeat vs. first-time buyers.\n",
    "3. Find best-performing products per region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Repeat vs. First-Time Buyers:\n",
      "    BuyerType  Count\n",
      "0  First-Time      6\n",
      "   CustomerID  PurchaseCount   BuyerType\n",
      "0          17              1  First-Time\n",
      "1          42              1  First-Time\n",
      "2          46              1  First-Time\n",
      "3          58              1  First-Time\n",
      "4          79              1  First-Time\n",
      "5          89              1  First-Time\n"
     ]
    }
   ],
   "source": [
    "# Compare repeat vs. first-time buyers\n",
    "\n",
    "# Identify repeat buyers\n",
    "repeat_buyers = purchases.groupby('CustomerID').size().reset_index(name='PurchaseCount')\n",
    "repeat_buyers['BuyerType'] = repeat_buyers['PurchaseCount'].apply(lambda x: 'Repeat' if x > 1 else 'First-Time')\n",
    "\n",
    "#  Count the number of first-time and repeat buyers\n",
    "buyer_type_counts = repeat_buyers.groupby('BuyerType').size().reset_index(name='Count')\n",
    "\n",
    "# Display the comparison\n",
    "print(\"Comparison of Repeat vs. First-Time Buyers:\")\n",
    "print(buyer_type_counts)\n",
    "print(repeat_buyers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-Performing Products Per Region:\n",
      "       Country  ProductID  PurchaseCount\n",
      "0      Austria         16              1\n",
      "1      Germany          2              1\n",
      "2  Netherlands         15              1\n",
      "3        Spain         17              1\n",
      "4       Sweden         15              1\n",
      "5           UK         17              1\n"
     ]
    }
   ],
   "source": [
    "# Merge customer purchases with geography data to analyze performance by region\n",
    "purchases_with_geography = pd.merge(purchases, customers, on='CustomerID')\n",
    "purchases_with_geography = pd.merge(purchases_with_geography, geography, on='GeographyID')\n",
    "\n",
    "# Group by region (Country) and ProductID to calculate total purchases\n",
    "region_product_performance = purchases_with_geography.groupby(['Country', 'ProductID']).size().reset_index(name='PurchaseCount')\n",
    "\n",
    "# Sort the results by region and purchase count in descending order\n",
    "region_product_performance = region_product_performance.sort_values(by=['Country', 'PurchaseCount'], ascending=[True, False])\n",
    "\n",
    "# Display the best-performing products per region\n",
    "print(\"Best-Performing Products Per Region:\")\n",
    "print(region_product_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
